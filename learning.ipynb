{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from fiery.models.encoder import Encoder\n",
    "from fiery.models.temporal_model import TemporalModelIdentity, TemporalModel\n",
    "from fiery.models.distributions import DistributionModule\n",
    "from fiery.models.future_prediction import FuturePrediction\n",
    "from fiery.models.decoder import Decoder\n",
    "from fiery.utils.network import pack_sequence_dim, unpack_sequence_dim, set_bn_momentum\n",
    "from fiery.utils.geometry import cumulative_warp_features, calculate_birds_eye_view_parameters, VoxelsSumming\n",
    "import visualise\n",
    "\n",
    "from fiery.trainer import TrainingModule\n",
    "from fiery.utils.network import NormalizeInverse\n",
    "from fiery.utils.instance import predict_instance_segmentation_and_trajectories\n",
    "from fiery.utils.visualisation import plot_instance_map, generate_instance_colours, make_contour, convert_figure_numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model I/O\n",
    "\n",
    "**image**: torch.Tensor float (T, N, 3, H, W) - normalised cameras images with T the sequence length, and N the number of cameras.\n",
    "\n",
    "**intrinsics**: torch.Tensor float (T, N, 3, 3) - intrinsics containing resizing and cropping parameters.\n",
    "\n",
    "**extrinsics**: torch.Tensor float  (T, N, 4, 4) - 6 DoF pose from world coordinates to camera coordinates.\n",
    "\n",
    "**future_egomotion**: torch.Tensor float (T, 6) - 6 DoF egomotion where  t -> t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slabban/anaconda3/envs/fiery/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/slabban/anaconda3/envs/fiery/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/slabban/anaconda3/envs/fiery/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (IntersectionOverUnion). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/slabban/anaconda3/envs/fiery/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PanopticMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingModule(\n",
       "  (model): Fiery(\n",
       "    (encoder): Encoder(\n",
       "      (backbone): EfficientNet(\n",
       "        (_conv_stem): Conv2dStaticSamePadding(\n",
       "          3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        (_blocks): ModuleList(\n",
       "          (0): MBConvBlock(\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (1): MBConvBlock(\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (2): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (3): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (4): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (5): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (6): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (7): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (8): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (9): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (10): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (11): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (12): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (13): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (14): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (15): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (16): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (17): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (18): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (19): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (20): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "          (21): MBConvBlock(\n",
       "            (_expand_conv): Conv2dStaticSamePadding(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "              (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "            )\n",
       "            (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_se_reduce): Conv2dStaticSamePadding(\n",
       "              960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_se_expand): Conv2dStaticSamePadding(\n",
       "              40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_project_conv): Conv2dStaticSamePadding(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (static_padding): Identity()\n",
       "            )\n",
       "            (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (_swish): MemoryEfficientSwish()\n",
       "          )\n",
       "        )\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (upsampling_layer): UpsamplingConcat(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(216, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (depth_layer): Conv2d(128, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (temporal_model): TemporalModel(\n",
       "      (model): Sequential(\n",
       "        (0): TemporalBlock(\n",
       "          (convolution_paths): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (conv): Conv3d(70, 35, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(35, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): CausalConv3d(\n",
       "                (pad): ConstantPad3d(padding=(1, 1, 1, 1, 1, 0), value=0)\n",
       "                (conv): Conv3d(35, 35, kernel_size=(2, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(35, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (conv): Conv3d(70, 35, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(35, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): CausalConv3d(\n",
       "                (pad): ConstantPad3d(padding=(1, 1, 1, 1, 0, 0), value=0)\n",
       "                (conv): Conv3d(35, 35, kernel_size=(1, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(35, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (conv): Conv3d(70, 35, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (norm): BatchNorm3d(35, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (aggregation): Sequential(\n",
       "            (0): Sequential(\n",
       "              (conv): Conv3d(105, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (norm): BatchNorm3d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (projection): Sequential(\n",
       "            (0): Conv3d(70, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): TemporalBlock(\n",
       "          (convolution_paths): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): CausalConv3d(\n",
       "                (pad): ConstantPad3d(padding=(1, 1, 1, 1, 1, 0), value=0)\n",
       "                (conv): Conv3d(32, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): CausalConv3d(\n",
       "                (pad): ConstantPad3d(padding=(1, 1, 1, 1, 0, 0), value=0)\n",
       "                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "                (norm): BatchNorm3d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (norm): BatchNorm3d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (aggregation): Sequential(\n",
       "            (0): Sequential(\n",
       "              (conv): Conv3d(96, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (norm): BatchNorm3d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (present_distribution): DistributionModule(\n",
       "      (encoder): DistributionEncoder(\n",
       "        (model): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(16, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (last_conv): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (future_distribution): DistributionModule(\n",
       "      (encoder): DistributionEncoder(\n",
       "        (model): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(88, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(44, 44, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(44, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(88, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(44, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(22, 22, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(22, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(44, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(44, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(22, 22, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(22, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(44, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(44, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(22, 22, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(22, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(22, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "            (projection): Sequential(\n",
       "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "              (conv_skip_proj): Conv2d(44, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn_skip_proj): BatchNorm2d(44, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (last_conv): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(44, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (future_prediction): FuturePrediction(\n",
       "      (spatial_grus): ModuleList(\n",
       "        (0): SpatialGRU(\n",
       "          (conv_update): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_reset): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_state_tilde): ConvBlock(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialGRU(\n",
       "          (conv_update): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_reset): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_state_tilde): ConvBlock(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): SpatialGRU(\n",
       "          (conv_update): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_reset): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_state_tilde): ConvBlock(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res_blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (layers): Sequential(\n",
       "              (conv_down_project): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_down_project): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (abn): Sequential(\n",
       "                (0): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv_up_project): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (abn_up_project): Sequential(\n",
       "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "              )\n",
       "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (first_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (up3_skip): UpsamplingAdd(\n",
       "        (upsample_layer): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "          (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (up2_skip): UpsamplingAdd(\n",
       "        (upsample_layer): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "          (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (up1_skip): UpsamplingAdd(\n",
       "        (upsample_layer): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (segmentation_head): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (instance_offset_head): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (instance_center_head): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (instance_future_head): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (losses_fn): ModuleDict(\n",
       "    (segmentation): SegmentationLoss()\n",
       "    (instance_center): SpatialRegressionLoss()\n",
       "    (instance_offset): SpatialRegressionLoss()\n",
       "    (instance_flow): SpatialRegressionLoss()\n",
       "    (probabilistic): ProbabilisticLoss()\n",
       "  )\n",
       "  (metric_iou_val): IntersectionOverUnion()\n",
       "  (metric_panoptic_val): PanopticMetric()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = TrainingModule.load_from_checkpoint('fiery.ckpt', strict=True)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "trainer = trainer.to(device)\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Image shape is 'torch.Size([1, 3, 6, 3, 224, 480])\n",
      "The Intrinsics shape is 'torch.Size([1, 3, 6, 3, 3])\n",
      "The Extrinsics shape is 'torch.Size([1, 3, 6, 4, 4])\n",
      "The Future Egomotions shape is 'torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Download and extract example input data\n",
    "visualise.download_example_data()\n",
    "\n",
    "EXAMPLE_DATA_PATH = 'example_data/example_1.npz'\n",
    "\n",
    "data = np.load(EXAMPLE_DATA_PATH)\n",
    "image = torch.from_numpy(data['image']).to(device)\n",
    "intrinsics = torch.from_numpy(data['intrinsics']).to(device)\n",
    "extrinsics = torch.from_numpy(data['extrinsics']).to(device)\n",
    "future_egomotions = torch.from_numpy(data['future_egomotion']).to(device)\n",
    "\n",
    "print(f\"The Image shape is '{image.shape}\")\n",
    "print(f\"The Intrinsics shape is '{intrinsics.shape}\")\n",
    "print(f\"The Extrinsics shape is '{extrinsics.shape}\")\n",
    "print(f\"The Future Egomotions shape is '{future_egomotions.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frustum Creation\n",
    "\n",
    "First, a frustum is created, which is a three-dimensional shape that is a pyramid with a flat top and base, and four triangular sides. The frustum is defined in terms of a grid in the image plane, and has three dimensions: left-right, top-bottom, and depth.\n",
    "\n",
    "The function first defines the height and width of the image plane, as well as the downsampled versions of these values. It then creates a depth grid by creating a 1D tensor of depth values between the bounds specified in the configuration (D_bound), and reshapes this tensor into a 3D tensor with dimensions (n_depth_slices, downsampled_h, downsampled_w).\n",
    "\n",
    "Next, the function creates x and y grids that are also 3D tensors with dimensions (n_depth_slices, downsampled_h, downsampled_w). These grids contain the x and y coordinates of each point in the image plane, respectively.\n",
    "\n",
    "Finally, the function stacks these three grids along the last dimension to create a frustum tensor with dimensions (n_depth_slices, downsampled_h, downsampled_w, 3). This tensor contains the x, y, and depth coordinates of each point in the frustum. The frustum tensor is then wrapped in a PyTorch nn.Parameter and returned. \n",
    "\n",
    "**_note_**: I noticed, however, that the shape of the final tensor has consistent x & y coordinates, making a rectangle and not a frustum shape. I beleive the shape is transformed to a frustum downstream in the 'get_geometry' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = (224, 480)\n",
    "encoder_downsample = 8\n",
    "D_bound = [2.0, 50.0, 1.0]\n",
    "def create_frustum():\n",
    "    # Create grid in image plane\n",
    "    h, w = image_dim\n",
    "    downsampled_h, downsampled_w = h // encoder_downsample, w // encoder_downsample\n",
    "\n",
    "    # Depth grid\n",
    "    depth_grid = torch.arange(*D_bound, dtype=torch.float)\n",
    "    depth_grid = depth_grid.view(-1, 1, 1).expand(-1, downsampled_h, downsampled_w)\n",
    "    n_depth_slices = depth_grid.shape[0]\n",
    "\n",
    "    # x and y grids\n",
    "    x_grid = torch.linspace(0, w - 1, downsampled_w, dtype=torch.float)\n",
    "    x_grid = x_grid.view(1, 1, downsampled_w).expand(n_depth_slices, downsampled_h, downsampled_w)\n",
    "    y_grid = torch.linspace(0, h - 1, downsampled_h, dtype=torch.float)\n",
    "    y_grid = y_grid.view(1, downsampled_h, 1).expand(n_depth_slices, downsampled_h, downsampled_w)\n",
    "\n",
    "    # Dimension (n_depth_slices, downsampled_h, downsampled_w, 3)\n",
    "    #containing data points in the image: left-right, top-bottom, depth\n",
    "    frustum = torch.stack((x_grid, y_grid, depth_grid), -1)\n",
    "    return nn.Parameter(frustum, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth grid shape is'torch.Size([48, 28, 60])\n",
      "tensor([[[ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         ...,\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.]],\n",
      "\n",
      "        [[ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "         [ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "         [ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "         ...,\n",
      "         [ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "         [ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "         [ 3.,  3.,  3.,  ...,  3.,  3.,  3.]],\n",
      "\n",
      "        [[ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         ...,\n",
      "         [ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  ...,  4.,  4.,  4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[47., 47., 47.,  ..., 47., 47., 47.],\n",
      "         [47., 47., 47.,  ..., 47., 47., 47.],\n",
      "         [47., 47., 47.,  ..., 47., 47., 47.],\n",
      "         ...,\n",
      "         [47., 47., 47.,  ..., 47., 47., 47.],\n",
      "         [47., 47., 47.,  ..., 47., 47., 47.],\n",
      "         [47., 47., 47.,  ..., 47., 47., 47.]],\n",
      "\n",
      "        [[48., 48., 48.,  ..., 48., 48., 48.],\n",
      "         [48., 48., 48.,  ..., 48., 48., 48.],\n",
      "         [48., 48., 48.,  ..., 48., 48., 48.],\n",
      "         ...,\n",
      "         [48., 48., 48.,  ..., 48., 48., 48.],\n",
      "         [48., 48., 48.,  ..., 48., 48., 48.],\n",
      "         [48., 48., 48.,  ..., 48., 48., 48.]],\n",
      "\n",
      "        [[49., 49., 49.,  ..., 49., 49., 49.],\n",
      "         [49., 49., 49.,  ..., 49., 49., 49.],\n",
      "         [49., 49., 49.,  ..., 49., 49., 49.],\n",
      "         ...,\n",
      "         [49., 49., 49.,  ..., 49., 49., 49.],\n",
      "         [49., 49., 49.,  ..., 49., 49., 49.],\n",
      "         [49., 49., 49.,  ..., 49., 49., 49.]]])\n"
     ]
    }
   ],
   "source": [
    "# Depth grid creation\n",
    "D_bound = [2.0, 50.0, 1.0]\n",
    "h, w = image_dim\n",
    "downsampled_h, downsampled_w = h // encoder_downsample, w // encoder_downsample\n",
    "\n",
    "depth_grid = torch.arange(*D_bound, dtype=torch.float)\n",
    "depth_grid = depth_grid.view(-1, 1, 1).expand(-1, downsampled_h, downsampled_w)\n",
    "n_depth_slices = depth_grid.shape[0]\n",
    "print(f\"The depth grid shape is'{depth_grid.shape}\")\n",
    "print(depth_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x grid grid shape is torch.Size([48, 28, 60])\n",
      "The y grid shape is torch.Size([48, 28, 60])\n"
     ]
    }
   ],
   "source": [
    "# x and y grids\n",
    "x_grid = torch.linspace(0, w - 1, downsampled_w, dtype=torch.float)\n",
    "x_grid = x_grid.view(1, 1, downsampled_w).expand(n_depth_slices, downsampled_h, downsampled_w)\n",
    "print(f\"The x grid grid shape is {x_grid.shape}\")\n",
    "y_grid = torch.linspace(0, h - 1, downsampled_h, dtype=torch.float)\n",
    "y_grid = y_grid.view(1, downsampled_h, 1).expand(n_depth_slices, downsampled_h, downsampled_w)\n",
    "print(f\"The y grid shape is {y_grid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The y frustum shape is torch.Size([48, 28, 60, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create frustum of Dimension (n_depth_slices, downsampled_h, downsampled_w, 3)\n",
    "#containing data points in the image: x, y, depth. The x and y values are the same here\n",
    "# This is not representative of the shape of a frustum, I beleive the frustum is created\n",
    "# Later on through scaling\n",
    "\n",
    "frustum = torch.stack((x_grid, y_grid, depth_grid), -1)\n",
    "print(f\"The y frustum shape is {frustum.shape}\")\n",
    "#print(frustum)\n",
    "#print(frustum[1,27])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Step 1: Lifting and Projecting Images to BEV\n",
    "\n",
    "The method that handles this operation is in the function 'calculate_birds_eye_view_features' as such:\n",
    "1. Packs the sequence dimensions with the batch size to process the images in a time-agnostic manner.\n",
    "2. Apply Intrinsic & Extrinsic Transformations to the Frustums to transform them to the ego frame\n",
    "3. Pass the images through the encoder to extract 2D features coupled with depth probabilities\n",
    "4. Project the images to BEV using the transformed frustums & images' features\n",
    "   using the 'splat' method of lift-splat-shoot paper.\n",
    "5. Unpack the sequence dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out to not crash computer\n",
    "#trainer.model.calculate_birds_eye_view_features(image, intrinsics, extrinsics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack sequence dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# The first step in this funtion is to pack the sequence dimension with the batches into one consolidate dimension\n",
    "\n",
    "b, s, n, c, h, w = image.shape\n",
    "# Reshape\n",
    "x = pack_sequence_dim(image)\n",
    "intrinsics = pack_sequence_dim(intrinsics)\n",
    "extrinsics = pack_sequence_dim(extrinsics)\n",
    "\n",
    "print(extrinsics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform from Camera Frustums to Ego Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The camera intriniscs and extrinsics are used to convert the images to the ego vehicle's reference frame \n",
    "# in the 'get_geometry' method as follows:\n",
    "\n",
    "def get_geometry(self, intrinsics, extrinsics):\n",
    "    \"\"\"Calculate the (x, y, z) 3D position of the features.\n",
    "    \"\"\"\n",
    "    rotation, translation = extrinsics[..., :3, :3], extrinsics[..., :3, 3]\n",
    "    B, N, _ = translation.shape\n",
    "    # Add batch, camera dimension, and a dummy dimension at the end\n",
    "    points = trainer.model.frustum.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "    # Camera to ego reference frame\n",
    "    points = torch.cat((points[:, :, :, :, :, :2] * points[:, :, :, :, :, 2:3], points[:, :, :, :, :, 2:3]), 5)\n",
    "    combined_transformation = rotation.matmul(torch.inverse(intrinsics))\n",
    "    points = combined_transformation.view(B, N, 1, 1, 1, 3, 3).matmul(points).squeeze(-1)\n",
    "    points += translation.view(B, N, 1, 1, 1, 3)\n",
    "\n",
    "    # The 3 dimensions in the ego reference frame are: (forward, sides, height)\n",
    "    return points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rotation shape is: torch.Size([3, 6, 3, 3])\n",
      "The translation shape is: torch.Size([3, 6, 3])\n",
      "The points shape is: torch.Size([1, 1, 48, 28, 60, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Lets dive into the function some more:\n",
    "\n",
    "rotation, translation = extrinsics[..., :3, :3], extrinsics[..., :3, 3]\n",
    "B, N, _ = translation.shape\n",
    "# Add batch, camera dimension, and a dummy dimension at the end\n",
    "points = trainer.model.frustum.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "print(f'The rotation shape is: {rotation.shape}')\n",
    "print(f'The translation shape is: {translation.shape}')\n",
    "print(f'The points shape is: {points.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frustum shape is torch.Size([1, 1, 48, 28, 60, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Camera to ego reference frame\n",
    "\n",
    "points = trainer.model.frustum.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "# x-y points extraction\n",
    "x_y = points[:, :, :, :, :, :2]\n",
    "#print(x_y)\n",
    "# depth extraction\n",
    "depth = points[:, :, :, :, :, 2:3]\n",
    "\n",
    "# The x and y points are being multiplied by the depth and concatenated along the depth axis \n",
    "# This could be the actual creation of the frustum since the x & y points are increasing at a scale\n",
    "# of the depth\n",
    "points = torch.cat((x_y*depth, depth), 5)\n",
    "print(f'The frustum shape is {points.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transformed frustums are returned transformed in the ego frame as: torch.Size([3, 6, 48, 28, 60, 3])\n"
     ]
    }
   ],
   "source": [
    "# Here we transform the frustum from the respective cameras to the ego frame of reference\n",
    "# The final 3 dimensions in the ego reference frame are: (forward, sides, height)\n",
    "\n",
    "combined_transformation = rotation.matmul(torch.inverse(intrinsics))\n",
    "points = combined_transformation.view(B, N, 1, 1, 1, 3, 3).matmul(points).squeeze(-1)\n",
    "points += translation.view(B, N, 1, 1, 1, 3)\n",
    "print(f'The transformed frustums are returned transformed in the ego frame as: {points.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Images\n",
    "\n",
    "EfficientNet (E) is chosen as the encoder for this model with an final convolutional layer that encodes feature channels and depth of each image(I), with (C) the number of feature channels, (D) the number of discrete depth values and (H, W) the feature spatial size.\n",
    "This feature is split into two: $e^{k}_{t}=(e^{k}_{t,C},e^{k}_{t,D})$ such that $e^{k}_{t,C}\\in\\mathbb{R}^{CxHxW}$ and $e^{k}_{t,D}\\in\\mathbb{R}^{DxHxW}$ and take their cross product to get the final output tensor of the encoder $u^{k}_{t}\\in\\mathbb{R}^{(CxDxHxW)}$\n",
    "The depth probabilities act as a form of self-attention, modulating the features according to which depth plane they are predicted to belong to. \n",
    "\n",
    "Fiery takes the output of the encoder as defined above and manipulates the tensors such that the final output is a tensor of $u^{k}_{t}\\in\\mathbb{R}^{BxNxDxHxWxC}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoder return tensor of shape : torch.Size([3, 6, 48, 28, 60, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = trainer.model.encoder_forward(x)\n",
    "print(f'The encoder return tensor of shape : {x.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project to BEV\n",
    "\n",
    "Following the method 'trainer.model.projection_to_birds_eye_view(x, points)', which is primarilty adapted from lift-splat-shoot at [this](https://github.com/nv-tlabs/lift-splat-shoot/blob/master/src/models.py#L200) point. \n",
    "\n",
    "The input data x is expected to be a tensor with dimensions B x N x D x H x W x C, where B is the batch size, N is the number of cameras or point clouds, D is the depth, H and W are the height and width, and C is the number of channels. The geometry represents the tensor containing the frustums, which is a tensor of 3D coordinates in the ego frame, with dimensions B x N x D x H x W x 3.\n",
    "\n",
    "We first establish the total number of 3D points based on the predicted encoder features $N_{total}$ =B x N x D x H x W\n",
    "\n",
    "We then loop through each batch and perform the following:\n",
    "\n",
    "1. First, the x_b tensor is flattened to a [$N_{total}$, C] tensor  so that all the points from all the cameras and point clouds are concatenated together. The geometry_b tensor is also flattened to the shape of [$N_{total}$, 3].\n",
    "2. Map geometry_b positions to the BEV grid\n",
    "3. A mask is determined based on the converted geometry_b and is applied to geometry_b and x_b to remove outlier points outside the set BEV grid\n",
    "4. Ranks are assigned to the geometry_b and x_b tensors such that the consecutive indices are within the same voxel, this structuring is an optimization step that simplifies voxel summing downstream\n",
    "5. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_to_birds_eye_view(self, x, geometry):\n",
    "    \"\"\" Adapted from https://github.com/nv-tlabs/lift-splat-shoot/blob/master/src/models.py#L200\"\"\"\n",
    "    # batch, n_cameras, depth, height, width, channels\n",
    "    batch, n, d, h, w, c = x.shape\n",
    "    output = torch.zeros(\n",
    "        (batch, c, self.bev_dimension[0], self.bev_dimension[1]), dtype=torch.float, device=x.device\n",
    "    )\n",
    "\n",
    "    # Number of 3D points\n",
    "    N = n * d * h * w\n",
    "    for b in range(batch):\n",
    "        # flatten x\n",
    "        x_b = x[b].reshape(N, c)\n",
    "\n",
    "        # Convert positions to integer indices\n",
    "        geometry_b = ((geometry[b] - (self.bev_start_position - self.bev_resolution / 2.0)) / self.bev_resolution)\n",
    "        geometry_b = geometry_b.view(N, 3).long()\n",
    "\n",
    "        # Mask out points that are outside the considered spatial extent.\n",
    "        mask = (\n",
    "                (geometry_b[:, 0] >= 0)\n",
    "                & (geometry_b[:, 0] < self.bev_dimension[0])\n",
    "                & (geometry_b[:, 1] >= 0)\n",
    "                & (geometry_b[:, 1] < self.bev_dimension[1])\n",
    "                & (geometry_b[:, 2] >= 0)\n",
    "                & (geometry_b[:, 2] < self.bev_dimension[2])\n",
    "        )\n",
    "        x_b = x_b[mask]\n",
    "        geometry_b = geometry_b[mask]\n",
    "\n",
    "        # Sort tensors so that those within the same voxel are consecutives.\n",
    "        ranks = (\n",
    "                geometry_b[:, 0] * (self.bev_dimension[1] * self.bev_dimension[2])\n",
    "                + geometry_b[:, 1] * (self.bev_dimension[2])\n",
    "                + geometry_b[:, 2]\n",
    "        )\n",
    "        ranks_indices = ranks.argsort()\n",
    "        x_b, geometry_b, ranks = x_b[ranks_indices], geometry_b[ranks_indices], ranks[ranks_indices]\n",
    "\n",
    "        # Project to bird's-eye view by summing voxels.\n",
    "        x_b, geometry_b = VoxelsSumming.apply(x_b, geometry_b, ranks)\n",
    "\n",
    "        bev_feature = torch.zeros((self.bev_dimension[2], self.bev_dimension[0], self.bev_dimension[1], c),\n",
    "                                    device=x_b.device)\n",
    "        bev_feature[geometry_b[:, 2], geometry_b[:, 0], geometry_b[:, 1]] = x_b\n",
    "\n",
    "        # Put channel in second position and remove z dimension\n",
    "        bev_feature = bev_feature.permute((0, 3, 1, 2))\n",
    "        bev_feature = bev_feature.squeeze(0)\n",
    "\n",
    "        output[b] = bev_feature\n",
    "\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by having a loook at the BEV dimensional attributes where:\n",
    "\n",
    "bev_resolution: Bird's-eye view bev_resolution\n",
    "\n",
    "bev_start_position: Bird's-eye view first element\n",
    "\n",
    "bev_dimension: Bird's-eye view tensor spatial dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEV resolution : Parameter containing:\n",
      "tensor([ 0.5000,  0.5000, 20.0000])\n",
      "BEV start position : Parameter containing:\n",
      "tensor([-49.7500, -49.7500,   0.0000])\n",
      "BEV dimensions x, y, z : 200, 200, 1\n"
     ]
    }
   ],
   "source": [
    "print(f'BEV resolution : {trainer.model.bev_resolution}')\n",
    "print(f'BEV start position : {trainer.model.bev_start_position}')\n",
    "print(f'BEV dimensions x, y, z : {trainer.model.bev_dimension[0]}, {trainer.model.bev_dimension[1]}, {trainer.model.bev_dimension[2]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets skip to the end of step 3 to undestand the ranking system looking at the 0th batch as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align variables to the function\n",
    "\n",
    "b = 0\n",
    "geometry = points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_b : torch.Size([452675, 64])\n",
      "geometry_b : torch.Size([452675, 3])\n"
     ]
    }
   ],
   "source": [
    "batch, n, d, h, w, c = x.shape\n",
    "output = torch.zeros(\n",
    "    (batch, c, trainer.model.bev_dimension[0], trainer.model.bev_dimension[1]), dtype=torch.float, device=x.device\n",
    ")\n",
    "\n",
    "# Number of 3D points\n",
    "N = n * d * h * w\n",
    "\n",
    "# flatten x\n",
    "x_b = x[b].reshape(N, c)\n",
    "\n",
    "# Convert positions to integer indices\n",
    "geometry_b = ((geometry[b] - (trainer.model.bev_start_position - trainer.model.bev_resolution / 2.0)) / trainer.model.bev_resolution)\n",
    "geometry_b = geometry_b.view(N, 3).long()\n",
    "\n",
    "# Mask out points that are outside the considered spatial extent.\n",
    "mask = (\n",
    "        (geometry_b[:, 0] >= 0)\n",
    "        & (geometry_b[:, 0] < trainer.model.bev_dimension[0])\n",
    "        & (geometry_b[:, 1] >= 0)\n",
    "        & (geometry_b[:, 1] < trainer.model.bev_dimension[1])\n",
    "        & (geometry_b[:, 2] >= 0)\n",
    "        & (geometry_b[:, 2] < trainer.model.bev_dimension[2])\n",
    ")\n",
    "x_b = x_b[mask]\n",
    "geometry_b = geometry_b[mask]\n",
    "\n",
    "print(f'x_b : {x_b.shape}')\n",
    "print(f'geometry_b : {geometry_b.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first assigns ranks to the each of the points in geometry_b by dot product of geometry_b[:,0], geometry_b[:,1],geometry_b[:,2] and (self.bev_dimension[1] * self.bev_dimension[2]), (self.bev_dimension[2]), 1 respectively which gives a unique rank for each tensor, based on its position within the BEV grid. \n",
    "\n",
    "The bev_dimension[1] * bev_dimension[2] term is used to account for the number of voxels in the y-z plane and is multiplied by the x-coordinate of the voxel to ensure that the x-coordinate has the greatest weight in the sorting. The bev_dimension[2] term is used to account for the number of voxels in the z-axis and is multiplied by the y-coordinate of the voxel. And finally, the z-coordinate of the voxel is added to the result. This way, the resulting 'ranks' variable will be a unique and consistent value for each voxel, and the indices of the sorted 'ranks' variable will correspond to the indices of the points sorted by their voxel location. \n",
    "\n",
    "It then uses the argsort() function to create an array called ranks_indices, which contains the indices that would sort the ranks array in ascending order.\n",
    "\n",
    "Finally, it uses these indices to sort the original tensors represented by the geometry_b array, as well as the x_b array and ranks array in the same order. This ensures that tensors that are located within the same voxel in the BEV grid are now consecutive in all three arrays.\n",
    "\n",
    "This way it is easy to process the groups of points which are located in same voxel, it also helps with faster processing as it reduces the iteration over the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort tensors so that those within the same voxel are consecutives.\n",
    "ranks = (\n",
    "        geometry_b[:, 0] * (trainer.model.bev_dimension[1] * trainer.model.bev_dimension[2])\n",
    "        + geometry_b[:, 1] * (trainer.model.bev_dimension[2])\n",
    "        + geometry_b[:, 2]\n",
    ")\n",
    "ranks_indices = ranks.argsort()\n",
    "x_b, geometry_b, ranks = x_b[ranks_indices], geometry_b[ranks_indices], ranks[ranks_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform the voxel summing operation which leverages what is called a 'cumulative sum trick'\n",
    "\n",
    "Taken as an excerpt from lift-splat-shoot:\n",
    "\n",
    "_The cumulative sum trick is the observation that sum pooling can be\n",
    "performed by sorting all points according to bin id, performing a cumulative sum\n",
    "over all features, then subtracting the cumulative sum values at the boundaries\n",
    "of the bin sections. Instead of relying on autograd to backprop through all three\n",
    "steps, the analytic gradient for the module as a whole can be derived, speeding up\n",
    "training by 2x. We call the layer Frustum Pooling because it handles converting\n",
    "the frustums produced by n images into a fixed dimensional H  W x C tensor (in fiery's case) \n",
    "independent of the number of cameras n._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__side note__: The implementation of this frustum pooling is shown below as the the 'VoxelSumming' subclass which inherits from the 'torch.autograd.Function'. This is the base class for all functions that compute gradients in PyTorch and is a fundamental building block for the PyTorch autograd system. When a function is executed in PyTorch, it creates a torch.autograd.Function object that computes the forward pass of the computation. The torch.autograd.Function object also holds the information necessary to compute the gradients of the computation with respect to the inputs using the backpropagation algorithm.\n",
    "\n",
    "There are two main methods that need to be implemented for any torch.autograd.Function subclass:\n",
    "\n",
    "1. forward(self, input): This method computes the forward pass of the function and stores the output tensors in the self.save_for_backward attribute.\n",
    "2. backward(self, grad_output): This method computes the gradients with respect to the inputs given the gradients with respect to the outputs. It should store the gradients in the self.grad_fn attribute of the corresponding input tensors.\n",
    "\n",
    "A common usage of torch.autograd.Function is when you want to implement a custom operation that is not natively supported by PyTorch or you want to add some custom behavior to the autograd system, for example for a custom loss function or custom layer in a neural network, in our case we are leveraging this function to capture our cumulative sum trick."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the implementation:\n",
    "\n",
    "A boolean mask called mask is created, with the same shape as x tensor. The mask tensor is filled with ones and is of type torch.bool\n",
    "The second line of code assigns the result of the comparison ranks[1:] != ranks[:-1] to a slice of the mask tensor. Specifically, it assigns the comparison to all elements of mask except the last one. The comparison ranks[1:] != ranks[:-1] compares each element of ranks[1:] with the corresponding element of ranks[:-1] and returns a tensor of the same shape as ranks[1:] with elements of type torch.bool that are True if the two elements are different and False otherwise.\n",
    "This mask is used to select only the elements in x and geometry that correspond to the change in voxel position, by using the mask to index the x and geometry tensor, this allows the forward method to only keep the first elements of each voxel and sum the feature for each voxel.\n",
    "\n",
    "The masked geomety_b tensor is kept for the final assignment of x_b to geometry_b features which occurs after the voxel summing, shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelsSumming(torch.autograd.Function):\n",
    "    \"\"\"Adapted from https://github.com/nv-tlabs/lift-splat-shoot/blob/master/src/tools.py#L193\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, geometry, ranks):\n",
    "        \"\"\"The features `x` and `geometry` are ranked by voxel positions.\"\"\"\n",
    "        # Cumulative sum of all features.\n",
    "        x = x.cumsum(0)\n",
    "\n",
    "        # Indicates the change of voxel.\n",
    "        mask = torch.ones(x.shape[0], device=x.device, dtype=torch.bool)\n",
    "        mask[:-1] = ranks[1:] != ranks[:-1]\n",
    "\n",
    "        x, geometry = x[mask], geometry[mask]\n",
    "        # Calculate sum of features within a voxel.\n",
    "        x = torch.cat((x[:1], x[1:] - x[:-1]))\n",
    "\n",
    "        ctx.save_for_backward(mask)\n",
    "        ctx.mark_non_differentiable(geometry)\n",
    "\n",
    "        return x, geometry\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_x, grad_geometry):\n",
    "        (mask,) = ctx.saved_tensors\n",
    "        # Since the operation is summing, we simply need to send gradient\n",
    "        # to all elements that were part of the summation process.\n",
    "        indices = torch.cumsum(mask, 0)\n",
    "        indices[mask] -= 1\n",
    "\n",
    "        output_grad = grad_x[indices]\n",
    "\n",
    "        return output_grad, None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we complete the bev projection by implementing the voxel summing static method and use the 'geometry_b' tensor to select the appropriate positions in the bev_feature tensor using advanced indexing. Specifically, it uses the values in the geometry_b[:, 2], geometry_b[:, 0], geometry_b[:, 1] as the indices to select the positions in the bev_feature tensor, and assigns the values of the x_b tensor to those positions. \n",
    "\n",
    "We perform some final permutations to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VoxelsSumming' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1636207/2289221305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVoxelsSumming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m bev_feature = torch.zeros((trainer.model.bev_dimension[2], trainer.model.bev_dimension[0], trainer.model.bev_dimension[1], c),\n\u001b[1;32m      4\u001b[0m                             device=x_b.device)\n\u001b[1;32m      5\u001b[0m \u001b[0mbev_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeometry_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VoxelsSumming' is not defined"
     ]
    }
   ],
   "source": [
    "x_b, geometry_b = VoxelsSumming.apply(x_b, geometry_b, ranks)\n",
    "\n",
    "bev_feature = torch.zeros((trainer.model.bev_dimension[2], trainer.model.bev_dimension[0], trainer.model.bev_dimension[1], c),\n",
    "                            device=x_b.device)\n",
    "bev_feature[geometry_b[:, 2], geometry_b[:, 0], geometry_b[:, 1]] = x_b\n",
    "\n",
    "# Put channel in second position and remove z dimension\n",
    "bev_feature = bev_feature.permute((0, 3, 1, 2))\n",
    "bev_feature = bev_feature.squeeze(0)\n",
    "\n",
    "output[b] = bev_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.undefined"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42b18f0de52ab44fca08e30efe98475ea9d3ba16d1e376f4f93b2d6d0f980eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
